{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook was created to test the results on smaller amount of estimators - this means faster generation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stat.gov.pl/statystyka-regionalna/rankingi-statystyczne/ludnosc-wedlug-wojewodztw/\n",
    "\n",
    "https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper as h\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "np.random.seed(2018)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "price_shift = 50000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_train = pd.read_hdf('../input/train_property.h5')\n",
    "orig_test = pd.read_hdf('../input/test_property.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_miasta = pd.read_csv('../externalData/statystyki-miasta-wiki.csv')\n",
    "stat_woj = pd.read_csv('../externalData/statystyki-woj.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 173 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n",
      "CPU times: user 14.3 s, sys: 3.84 ms, total: 14.3 s\n",
      "Wall time: 14.3 s\n",
      "CPU times: user 72.4 ms, sys: 4.16 ms, total: 76.5 ms\n",
      "Wall time: 72.4 ms\n",
      "CPU times: user 74.1 ms, sys: 8.08 ms, total: 82.2 ms\n",
      "Wall time: 77.3 ms\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "def norm_date(value):\n",
    "    if value is None: return value\n",
    "    \n",
    "    months_to_digit = {\n",
    "        'stycznia': 1,\n",
    "        'lutego': 2,\n",
    "        'marca': 3,\n",
    "        'kwietnia': 4,\n",
    "        'maja': 5,\n",
    "        'czerwca': 6,\n",
    "        'lipca': 7,\n",
    "        'sierpnia': 8,\n",
    "        'września': 9,\n",
    "        'października': 10,\n",
    "        'listopada': 11,\n",
    "        'grudnia': 12\n",
    "    }\n",
    "    values = value.split(' ')\n",
    "\n",
    "    day   = int(values[0]) if len(values) == 3 else None\n",
    "    month = values[-2].lower()\n",
    "    year  = int(values[-1])\n",
    "\n",
    "    month = months_to_digit[month]\n",
    "\n",
    "    return (year*100 + month)\n",
    "\n",
    "\n",
    "def map_city(x):\n",
    "    if (len(x) == 2):\n",
    "        if x[1] in miasta_ll_dict:\n",
    "            return x[1]\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    if (len(x)>2):\n",
    "        if x[2] in miasta_ll_dict:\n",
    "            return x[2]\n",
    "        elif x[1] in miasta_ll_dict:\n",
    "            return x[1]\n",
    "        else: \n",
    "            return 'unknown'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "def get_visit_ads(x):\n",
    "    if 'visit_ads' in x:\n",
    "        return np.log( int(x['visit_ads']) + 10 )\n",
    "    return -1\n",
    "\n",
    "#\n",
    "# extract price from the 'text' field\n",
    "#\n",
    "def extract_largest_value(x):\n",
    "    formated = x.lower().replace('m2','').replace(' ','')\n",
    "    digits = re.split(\"\\D\", formated)\n",
    "    max_value = 0\n",
    "    if x.lower().find('cena') > 0: # only if there is 'cena' in text\n",
    "        for i in digits:\n",
    "            if i.isdigit():\n",
    "                if len(i) < 7: # skip telephone numbers and other identifiers\n",
    "                    if int(i) < 1000000: # skip too high values\n",
    "                        max_value = max(int(i),max_value)\n",
    "\n",
    "        if max_value > 100000: # skip too small values\n",
    "            return(max_value)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "##########################################################################\n",
    "#\n",
    "# Categorize function\n",
    "#\n",
    "\n",
    "def categorize_feature(df, feat, feat_cat, indexers, del_feat=True, average_func=np.median, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    if feat in indexers:\n",
    "        return categorize_feature_for_test(df, feat, feat_cat, indexers[feat], del_feat=del_feat, unknown_cat_name=unknown_cat_name, unknown_cat_val=unknown_cat_val)\n",
    "    \n",
    "    categories_map = categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=del_feat, unknown_cat_name=unknown_cat_name)\n",
    "    \n",
    "def categorize_feature_for_test(df, feat, feat_cat, categories_map, del_feat=True, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    df[feat_cat] = [categories_map[x] if x in categories_map \n",
    "                    else categories_map[unknown_cat_name] if unknown_cat_name in categories_map \n",
    "                    else unknown_cat_val for x in df[feat]]\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]\n",
    "    \n",
    "def categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=True, unknown_cat_name='unknown'):\n",
    "    df.loc[df[feat].isnull(), feat] = unknown_cat_name\n",
    "\n",
    "    unique_categories = sorted(list(set(df[feat])),key=str)\n",
    "    \n",
    "    categories_map = {}\n",
    "\n",
    "    for i, (cat) in enumerate(unique_categories):\n",
    "        categories_map[cat] = i\n",
    "\n",
    "    for cat, ind in categories_map.items():\n",
    "        df.loc[df[feat] == cat, feat_cat] = ind\n",
    "\n",
    "    indexers[feat] = categories_map\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]\n",
    "\n",
    "##########################################################################\n",
    "#\n",
    "# Data preparation\n",
    "#\n",
    "\n",
    "def perform_engineering(df, train_indexers=None):\n",
    "    indexers = train_indexers if train_indexers != None else {}\n",
    "    \n",
    "    df['area_float'] = df['area'].map(lambda x: float(re.sub('[^0-9\\,\\.]','', x).replace(',', '.')))\n",
    "    df['area_fixed'] = df['area_float'].map(lambda x: x if x > 0 else 60)\n",
    "    df['floor_int'] = df['floor'].map({'parter':0, '1':1, '2':2, '3':3, -1:-1, '4':4, \n",
    "                                       '7':7, '5':5, '10':10, '8':8, '6':6, '9':9,'> 10':11, \n",
    "                                       'poddasze':12, 'suterena':-2})\n",
    "    df['floors_in_int'] = df['floors_in_building'].map(lambda x: \n",
    "                                                       int(re.sub('[^0-9\\,\\.]','', x)) if x != -1 else -1 )\n",
    "    df['rok_budowy_int'] = df['rok budowy'].map(lambda x: int(re.sub('[^0-9\\,\\.]','', x)) if x != -1 else -1 )\n",
    "    df['czynsz_float'] = df['czynsz'].map(lambda x: \n",
    "                                          float(re.sub('[^0-9\\,\\.]','', x).replace(',', '.')) if x != -1 else x )\n",
    "    \n",
    "    #\n",
    "    # LOCATION\n",
    "    #\n",
    "    df['location_v'] = df['location'].map(lambda x: x[0])\n",
    "    df['location_c'] = df['location'].map(lambda x: x[0] + \", \" + x[1])\n",
    "    df['location_cc'] = df['location'].map(\n",
    "            lambda x: x[0] + \", \" + x[1] + \", \" + x[2] if len(x)>2 else x[0] + \", \" + x[1])  \n",
    "    df['location_powiat'] = df['location'].map(lambda x: x[1] if x[1][-1]=='i' else 'unknown')\n",
    "    df['location_miasto'] = df['location'].map(map_city)\n",
    "    \n",
    "    df['miasto_ludnosc'] = df['location_miasto'].map(miasta_ll_dict)\n",
    "    df['miasto_gestosc'] = df['location_miasto'].map(miasta_gz_dict)\n",
    "    df['miasto_powierzchnia'] = df['location_miasto'].map(miasta_pow_dict)\n",
    "    df['wojewodztwo_ludnosc'] = df['location_v'].map(wojewodztwa_ll)\n",
    "    \n",
    "    categorize_feature(df, 'location_v', 'location_v_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_c', 'location_c_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_cc', 'location_cc_cat', indexers=indexers)\n",
    "\n",
    "    categorize_feature(df, 'location_powiat', 'location_powiat_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_miasto', 'location_miasto_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # Stats\n",
    "    #\n",
    "    \n",
    "    df['stats_created_at'] = df['stats'].map(lambda x: x['created_at'])\n",
    "    df['stats_updated_at'] = df['stats'].map(lambda x: x['updated_at'])\n",
    "    df['stats_visit_ads'] = df['stats'].map(get_visit_ads)\n",
    "    \n",
    "    categorize_feature(df, 'stats_created_at', 'stats_created_at_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'stats_updated_at', 'stats_updated_at_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # text field - price extraction from the text\n",
    "    #\n",
    "    \n",
    "    df['largest_value'] = df['text'].map(extract_largest_value)\n",
    "    \n",
    "    #\n",
    "    # categorization\n",
    "    #\n",
    "    categorize_feature(df, 'materiał budynku', 'material_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'okna', 'okna_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'stan wykończenia', 'stan_wyk_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'rodzaj zabudowy', 'rodzaj_zabudowy_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'ogrzewanie', 'ogrzewanie_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'forma własności', 'forma_wlasnosci_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # cleanup\n",
    "    #\n",
    "    columns_to_remove = ['area', 'location', 'data rozpoczęcia', 'stan inwestycji', 'liczba kondygnacji',\n",
    "                         'floor','floors_in_building','rok budowy', 'czynsz', 'dostępne od',\n",
    "                         'garaż', 'tarasy', 'ochrona', 'stats', 'text', 'rolety antywłamaniowe', \n",
    "                         'kuchenka', 'klimatyzacja', 'plan zagospodarowania:',\n",
    "                         'telefon', 'telewizja kablowa', 'pom. użytkowe', 'pralka', 'piekarnik',\n",
    "                         'lodówka', 'ogródek', 'drzwi / okna antywłamaniowe'\n",
    "                        ]\n",
    "    for col_to_remove in columns_to_remove:\n",
    "        if col_to_remove in df: del df[col_to_remove]\n",
    "\n",
    "    return df, indexers\n",
    "\n",
    "def price_engineering(df):\n",
    "    df['lv_mean'] = df['location_v_cat'].map(dict_mean_price_by_LV)\n",
    "    df['lv_median'] = df['location_v_cat'].map(dict_median_price_by_LV)\n",
    "    df['lc_mean'] = df['location_c_cat'].map(dict_mean_price_by_LC)\n",
    "    df['lc_median'] = df['location_c_cat'].map(dict_median_price_by_LC)\n",
    "    df['lc_mean'] = df['lc_mean'].fillna(df['lv_mean'])\n",
    "    df['lc_median'] = df['lc_median'].fillna(df['lv_median'])\n",
    "    df['lcc_mean'] = df['location_cc_cat'].map(dict_mean_price_by_LCC)\n",
    "    df['lcc_median'] = df['location_cc_cat'].map(dict_median_price_by_LCC)\n",
    "    df['lcc_mean'] = df['lcc_mean'].fillna(df['lc_mean'])\n",
    "    df['lcc_median'] = df['lcc_median'].fillna(df['lc_median'])\n",
    "\n",
    "    df['lv_mean_price_calculated'] = df['lv_mean'] * df['area_fixed']\n",
    "    df['lv_median_price_calculated'] = df['lv_median'] * df['area_fixed']\n",
    "    df['lc_mean_price_calculated'] = df['lc_mean'] * df['area_fixed']\n",
    "    df['lc_median_price_calculated'] = df['lc_median'] * df['area_fixed']\n",
    "    df['lcc_mean_price_calculated'] = df['lcc_mean'] * df['area_fixed']\n",
    "    df['lcc_median_price_calculated'] = df['lcc_median'] * df['area_fixed']   \n",
    "    \n",
    "    #\n",
    "    # cleanup\n",
    "    #\n",
    "    columns_to_remove = ['price_per_meter']\n",
    "    for col_to_remove in columns_to_remove:\n",
    "        if col_to_remove in df: del df[col_to_remove]\n",
    "\n",
    "            \n",
    "## statistics\n",
    "miasta_gz_dict = stat_miasta.groupby('Miasto').agg(np.median)['Gęstość zaludnienia'].to_dict()\n",
    "miasta_ll_dict = stat_miasta.groupby('Miasto').agg(np.median)['Liczba ludności'].to_dict()\n",
    "miasta_pow_dict = stat_miasta.groupby('Miasto').agg(np.median)['Powierzchnia'].to_dict()\n",
    "wojewodztwa_ll = stat_woj.groupby('Województwo').agg(np.median)['Ogółem'].to_dict()\n",
    "            \n",
    "## restore from copy\n",
    "train = orig_train.copy()\n",
    "test = orig_test.copy()\n",
    "\n",
    "## fill NA\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "## prepare data\n",
    "%time train, indexers = perform_engineering(train)\n",
    "%time test, dummy = perform_engineering(test, indexers)\n",
    "\n",
    "## train specific (only for train)\n",
    "train['price_per_meter'] = train['price'] / train['area_fixed']\n",
    "\n",
    "dict_mean_price_by_LV = train.groupby('location_v_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LV = train.groupby('location_v_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "dict_mean_price_by_LC = train.groupby('location_c_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LC = train.groupby('location_c_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "dict_mean_price_by_LCC = train.groupby('location_cc_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LCC = train.groupby('location_cc_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "\n",
    "## prepare price related data\n",
    "%time price_engineering(train)\n",
    "%time price_engineering(test)\n",
    "\n",
    "## fill NA\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  ['monitoring / ochrona', 'taras', 'balkon', 'dwupoziomowe', 'system alarmowy', 'teren zamknięty', 'internet', 'winda', 'piwnica', 'telewizor', 'domofon / wideofon', 'oddzielna kuchnia', 'zmywarka', 'garaż/miejsce parkingowe', 'meble', 'is_primary_market', 'area_float', 'area_fixed', 'rok_budowy_int', 'czynsz_float', 'miasto_ludnosc', 'miasto_gestosc', 'miasto_powierzchnia', 'wojewodztwo_ludnosc', 'stats_visit_ads', 'largest_value', 'lv_mean', 'lv_median', 'lc_mean', 'lc_median', 'lcc_mean', 'lcc_median', 'lv_mean_price_calculated', 'lv_median_price_calculated', 'lc_mean_price_calculated', 'lc_median_price_calculated', 'lcc_mean_price_calculated', 'lcc_median_price_calculated', 'location_v_cat', 'location_c_cat', 'location_cc_cat', 'location_powiat_cat', 'location_miasto_cat', 'stats_created_at_cat', 'stats_updated_at_cat', 'material_cat', 'okna_cat', 'stan_wyk_cat', 'rodzaj_zabudowy_cat', 'ogrzewanie_cat', 'forma_wlasnosci_cat', 'rooms', 'is_private', 'floor_int', 'floors_in_int']\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "#\n",
    "# PREPARE FEATURES\n",
    "#\n",
    "\n",
    "black_list = ['price', 'id']\n",
    "\n",
    "bool_features = train.select_dtypes(include=[np.bool]).columns.values.tolist()\n",
    "\n",
    "cat_feats = [feat for feat in train.columns if 'cat' in feat]\n",
    "cat_feats = cat_feats + ['rooms', 'is_private', 'floor_int', 'floors_in_int']\n",
    "\n",
    "numeric_features = train.select_dtypes(include=[np.float64, np.int64, np.int8]).columns.values\n",
    "numeric_features = [feat for feat in numeric_features if feat not in (black_list + cat_feats) ]\n",
    "\n",
    "feats = bool_features + numeric_features + cat_feats\n",
    "\n",
    "feats = [feat for feat in feats if feat not in (black_list)]\n",
    "print(\"Selected features: \", feats)\n",
    "\n",
    "X = train[ feats ].values\n",
    "y = train[ 'price' ].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global fair_constant \n",
    "\n",
    "def fair_obj(y_true, y_pred):\n",
    "    x = y_pred - y_true\n",
    "    \n",
    "    global fair_constant \n",
    "\n",
    "    den = abs(x) + fair_constant\n",
    "    \n",
    "    grad = fair_constant * x / den\n",
    "    hess = (fair_constant * fair_constant) / (den * den)\n",
    "    \n",
    "    return grad, hess\n",
    "\n",
    "xgb_params_1 = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 8, \n",
    "    'n_estimators': 1650, \n",
    "    'learning_rate': 0.04, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 4096\n",
    "}\n",
    "\n",
    "xgb_params_2 = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 14, \n",
    "    'n_estimators': 277, \n",
    "    'learning_rate': 0.056693922378212164, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 2018\n",
    "}\n",
    "\n",
    "xgb_params_s = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 8, \n",
    "    'n_estimators': 132, \n",
    "    'learning_rate': 0.05, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 2018\n",
    "}\n",
    "\n",
    "shift = price_shift\n",
    "fair_constant = 13259.556042072305\n",
    "y_log = np.log(y + shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first training finished\n",
      "second training finished\n",
      "stacked training finished, ready to predict\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## first one\n",
    "##\n",
    "\n",
    "modelXGB1 = XGBRegressor(**xgb_params_1)\n",
    "modelXGB1.fit(X, y_log, verbose=100)\n",
    "    \n",
    "print('first training finished')    \n",
    "    \n",
    "##\n",
    "## second one\n",
    "##\n",
    "\n",
    "modelXGB2 = XGBRegressor(**xgb_params_2)\n",
    "modelXGB2.fit(X, y_log, verbose=50)\n",
    "\n",
    "print('second training finished')\n",
    "\n",
    "#\n",
    "# generate new columns for stacked XGB\n",
    "#\n",
    "train['XGB_1_results'] = modelXGB1.predict(X)\n",
    "train['XGB_2_results'] = modelXGB2.predict(X)\n",
    "\n",
    "stacked_feats = feats + ['XGB_1_results', 'XGB_2_results']\n",
    "\n",
    "X_stacked = train[ stacked_feats ].values\n",
    "y_stacked = train[ 'price' ].values\n",
    "\n",
    "y_stacked_log = np.log(y_stacked + shift)\n",
    "\n",
    "modelXGB_s = XGBRegressor(**xgb_params_s)\n",
    "modelXGB_s.fit(X_stacked, y_stacked_log, verbose=10)\n",
    "\n",
    "print('stacked training finished, ready to predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB predictions stacked:  [ 288561.16  313312.47  568389.75 ... 1158472.2   497636.75  550682.9 ]\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# LOG ANSWERS\n",
    "#\n",
    "\n",
    "def modPrice(x,limit):\n",
    "    if x['largest_value'] == 0:\n",
    "        return x['price']\n",
    "    if (abs(x['price'] - x['largest_value']) < limit):\n",
    "        return x['largest_value']\n",
    "    \n",
    "    return x['price']\n",
    "\n",
    "#\n",
    "# stacking\n",
    "# \n",
    "test['XGB_1_results'] = modelXGB1.predict(test[ feats ].values)\n",
    "test['XGB_2_results'] = modelXGB2.predict(test[ feats ].values)\n",
    "stacked_feats = feats + ['XGB_1_results', 'XGB_2_results']\n",
    "y_pred_log = modelXGB_s.predict(test[ stacked_feats ].values)\n",
    "y_pred = np.exp( y_pred_log ) - shift\n",
    "print(\"XGB predictions stacked: \",y_pred)\n",
    "test['priceXGB_s'] = y_pred\n",
    "\n",
    "#\n",
    "# modify price with limit of 225000\n",
    "#\n",
    "test['price'] =  test['priceXGB_s']\n",
    "test['price_s_mod'] = test.apply(lambda x: modPrice(x,225000), axis=1 )\n",
    "test['price'] = test['price_s_mod']\n",
    "test[ ['id', 'price'] ].to_csv('../output/FINAL_estimators66_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.csv', index=False) \n",
    "\n",
    "print(\"FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
