{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook was used to calculate Cross Validation scores for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stat.gov.pl/statystyka-regionalna/rankingi-statystyczne/ludnosc-wedlug-wojewodztw/\n",
    "\n",
    "https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper as h\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "np.random.seed(2018)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "price_shift = 50000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_hdf('../input/train_property.h5')\n",
    "test = pd.read_hdf('../input/test_property.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_miasta = pd.read_csv('../externalData/statystyki-miasta-wiki.csv')\n",
    "stat_woj = pd.read_csv('../externalData/statystyki-woj.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 165 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n",
      "CPU times: user 14 s, sys: 19.6 ms, total: 14 s\n",
      "Wall time: 14 s\n",
      "CPU times: user 95.6 ms, sys: 4.26 ms, total: 99.9 ms\n",
      "Wall time: 93.5 ms\n",
      "CPU times: user 103 ms, sys: 250 µs, total: 104 ms\n",
      "Wall time: 95.9 ms\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "def norm_date(value):\n",
    "    if value is None: return value\n",
    "    \n",
    "    months_to_digit = {\n",
    "        'stycznia': 1,\n",
    "        'lutego': 2,\n",
    "        'marca': 3,\n",
    "        'kwietnia': 4,\n",
    "        'maja': 5,\n",
    "        'czerwca': 6,\n",
    "        'lipca': 7,\n",
    "        'sierpnia': 8,\n",
    "        'września': 9,\n",
    "        'października': 10,\n",
    "        'listopada': 11,\n",
    "        'grudnia': 12\n",
    "    }\n",
    "    values = value.split(' ')\n",
    "\n",
    "    day   = int(values[0]) if len(values) == 3 else None\n",
    "    month = values[-2].lower()\n",
    "    year  = int(values[-1])\n",
    "\n",
    "    month = months_to_digit[month]\n",
    "\n",
    "    return (year*100 + month)\n",
    "\n",
    "\n",
    "def map_city(x):\n",
    "    if (len(x) == 2):\n",
    "        if x[1] in miasta_ll_dict:\n",
    "            return x[1]\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    if (len(x)>2):\n",
    "        if x[2] in miasta_ll_dict:\n",
    "            return x[2]\n",
    "        elif x[1] in miasta_ll_dict:\n",
    "            return x[1]\n",
    "        else: \n",
    "            return 'unknown'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "def get_visit_ads(x):\n",
    "    if 'visit_ads' in x:\n",
    "        return np.log( int(x['visit_ads']) + 10 )\n",
    "    return -1\n",
    "\n",
    "#\n",
    "# extract price from the 'text' field\n",
    "#\n",
    "def extract_largest_value(x):\n",
    "    formated = x.lower().replace('m2','').replace(' ','')\n",
    "    digits = re.split(\"\\D\", formated)\n",
    "    max_value = 0\n",
    "    if x.lower().find('cena') > 0: # only if there is 'cena' in text\n",
    "        for i in digits:\n",
    "            if i.isdigit():\n",
    "                if len(i) < 7: # skip telephone numbers and other identifiers\n",
    "                    if int(i) < 1000000: # skip too high values\n",
    "                        max_value = max(int(i),max_value)\n",
    "\n",
    "        if max_value > 100000: # skip too small values\n",
    "            return(max_value)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "##########################################################################\n",
    "#\n",
    "# Categorize function\n",
    "#\n",
    "\n",
    "def categorize_feature(df, feat, feat_cat, indexers, del_feat=True, average_func=np.median, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    if feat in indexers:\n",
    "        return categorize_feature_for_test(df, feat, feat_cat, indexers[feat], del_feat=del_feat, unknown_cat_name=unknown_cat_name, unknown_cat_val=unknown_cat_val)\n",
    "    \n",
    "    categories_map = categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=del_feat, unknown_cat_name=unknown_cat_name)\n",
    "    \n",
    "def categorize_feature_for_test(df, feat, feat_cat, categories_map, del_feat=True, unknown_cat_name='unknown', unknown_cat_val=-1):\n",
    "    df[feat_cat] = [categories_map[x] if x in categories_map \n",
    "                    else categories_map[unknown_cat_name] if unknown_cat_name in categories_map \n",
    "                    else unknown_cat_val for x in df[feat]]\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]\n",
    "    \n",
    "def categorize_feature_for_train(df, feat, feat_cat, indexers, del_feat=True, unknown_cat_name='unknown'):\n",
    "    df.loc[df[feat].isnull(), feat] = unknown_cat_name\n",
    "\n",
    "    unique_categories = sorted(list(set(df[feat])),key=str)\n",
    "    \n",
    "    categories_map = {}\n",
    "\n",
    "    for i, (cat) in enumerate(unique_categories):\n",
    "        categories_map[cat] = i\n",
    "\n",
    "    for cat, ind in categories_map.items():\n",
    "        df.loc[df[feat] == cat, feat_cat] = ind\n",
    "\n",
    "    indexers[feat] = categories_map\n",
    "    \n",
    "    if del_feat:\n",
    "        del df[feat]\n",
    "\n",
    "##########################################################################\n",
    "#\n",
    "# Data preparation\n",
    "#\n",
    "\n",
    "def perform_engineering(df, train_indexers=None):\n",
    "    indexers = train_indexers if train_indexers != None else {}\n",
    "    \n",
    "    df['area_float'] = df['area'].map(lambda x: float(re.sub('[^0-9\\,\\.]','', x).replace(',', '.')))\n",
    "    df['area_fixed'] = df['area_float'].map(lambda x: x if x > 0 else 60)\n",
    "    df['floor_int'] = df['floor'].map({'parter':0, '1':1, '2':2, '3':3, -1:-1, '4':4, \n",
    "                                       '7':7, '5':5, '10':10, '8':8, '6':6, '9':9,'> 10':11, \n",
    "                                       'poddasze':12, 'suterena':-2})\n",
    "    df['floors_in_int'] = df['floors_in_building'].map(lambda x: \n",
    "                                                       int(re.sub('[^0-9\\,\\.]','', x)) if x != -1 else -1 )\n",
    "    df['rok_budowy_int'] = df['rok budowy'].map(lambda x: int(re.sub('[^0-9\\,\\.]','', x)) if x != -1 else -1 )\n",
    "    df['czynsz_float'] = df['czynsz'].map(lambda x: \n",
    "                                          float(re.sub('[^0-9\\,\\.]','', x).replace(',', '.')) if x != -1 else x )\n",
    "    \n",
    "    #\n",
    "    # LOCATION\n",
    "    #\n",
    "    df['location_v'] = df['location'].map(lambda x: x[0])\n",
    "    df['location_c'] = df['location'].map(lambda x: x[0] + \", \" + x[1])\n",
    "    df['location_cc'] = df['location'].map(\n",
    "            lambda x: x[0] + \", \" + x[1] + \", \" + x[2] if len(x)>2 else x[0] + \", \" + x[1])  \n",
    "    df['location_powiat'] = df['location'].map(lambda x: x[1] if x[1][-1]=='i' else 'unknown')\n",
    "    df['location_miasto'] = df['location'].map(map_city)\n",
    "    \n",
    "    df['miasto_ludnosc'] = df['location_miasto'].map(miasta_ll_dict)\n",
    "    df['miasto_gestosc'] = df['location_miasto'].map(miasta_gz_dict)\n",
    "    df['miasto_powierzchnia'] = df['location_miasto'].map(miasta_pow_dict)\n",
    "    df['wojewodztwo_ludnosc'] = df['location_v'].map(wojewodztwa_ll)\n",
    "    \n",
    "    categorize_feature(df, 'location_v', 'location_v_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_c', 'location_c_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_cc', 'location_cc_cat', indexers=indexers)\n",
    "\n",
    "    categorize_feature(df, 'location_powiat', 'location_powiat_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'location_miasto', 'location_miasto_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # Stats\n",
    "    #\n",
    "    \n",
    "    df['stats_created_at'] = df['stats'].map(lambda x: x['created_at'])\n",
    "    df['stats_updated_at'] = df['stats'].map(lambda x: x['updated_at'])\n",
    "    df['stats_visit_ads'] = df['stats'].map(get_visit_ads)\n",
    "    \n",
    "    categorize_feature(df, 'stats_created_at', 'stats_created_at_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'stats_updated_at', 'stats_updated_at_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # text field - price extraction from the text\n",
    "    #\n",
    "    \n",
    "    df['largest_value'] = df['text'].map(extract_largest_value)\n",
    "    \n",
    "    #\n",
    "    # categorization\n",
    "    #\n",
    "    categorize_feature(df, 'materiał budynku', 'material_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'okna', 'okna_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'stan wykończenia', 'stan_wyk_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'rodzaj zabudowy', 'rodzaj_zabudowy_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'ogrzewanie', 'ogrzewanie_cat', indexers=indexers)\n",
    "    categorize_feature(df, 'forma własności', 'forma_wlasnosci_cat', indexers=indexers)\n",
    "    \n",
    "    #\n",
    "    # cleanup\n",
    "    #\n",
    "    columns_to_remove = ['area', 'location', 'data rozpoczęcia', 'stan inwestycji', 'liczba kondygnacji',\n",
    "                         'floor','floors_in_building','rok budowy', 'czynsz', 'dostępne od',\n",
    "                         'garaż', 'tarasy', 'ochrona', 'stats', 'text', 'rolety antywłamaniowe', \n",
    "                         'kuchenka', 'klimatyzacja', 'plan zagospodarowania:',\n",
    "                         'telefon', 'telewizja kablowa', 'pom. użytkowe', 'pralka', 'piekarnik',\n",
    "                         'lodówka', 'ogródek', 'drzwi / okna antywłamaniowe'\n",
    "                        ]\n",
    "    for col_to_remove in columns_to_remove:\n",
    "        if col_to_remove in df: del df[col_to_remove]\n",
    "\n",
    "    return df, indexers\n",
    "\n",
    "def price_engineering(df):\n",
    "    df['lv_mean'] = df['location_v_cat'].map(dict_mean_price_by_LV)\n",
    "    df['lv_median'] = df['location_v_cat'].map(dict_median_price_by_LV)\n",
    "    df['lc_mean'] = df['location_c_cat'].map(dict_mean_price_by_LC)\n",
    "    df['lc_median'] = df['location_c_cat'].map(dict_median_price_by_LC)\n",
    "    df['lc_mean'] = df['lc_mean'].fillna(df['lv_mean'])\n",
    "    df['lc_median'] = df['lc_median'].fillna(df['lv_median'])\n",
    "    df['lcc_mean'] = df['location_cc_cat'].map(dict_mean_price_by_LCC)\n",
    "    df['lcc_median'] = df['location_cc_cat'].map(dict_median_price_by_LCC)\n",
    "    df['lcc_mean'] = df['lcc_mean'].fillna(df['lc_mean'])\n",
    "    df['lcc_median'] = df['lcc_median'].fillna(df['lc_median'])\n",
    "\n",
    "    df['lv_mean_price_calculated'] = df['lv_mean'] * df['area_fixed']\n",
    "    df['lv_median_price_calculated'] = df['lv_median'] * df['area_fixed']\n",
    "    df['lc_mean_price_calculated'] = df['lc_mean'] * df['area_fixed']\n",
    "    df['lc_median_price_calculated'] = df['lc_median'] * df['area_fixed']\n",
    "    df['lcc_mean_price_calculated'] = df['lcc_mean'] * df['area_fixed']\n",
    "    df['lcc_median_price_calculated'] = df['lcc_median'] * df['area_fixed']   \n",
    "    \n",
    "    #\n",
    "    # cleanup\n",
    "    #\n",
    "    columns_to_remove = ['price_per_meter']\n",
    "    for col_to_remove in columns_to_remove:\n",
    "        if col_to_remove in df: del df[col_to_remove]\n",
    "\n",
    "#########################################\n",
    "#            \n",
    "# statistics\n",
    "#\n",
    "miasta_gz_dict = stat_miasta.groupby('Miasto').agg(np.median)['Gęstość zaludnienia'].to_dict()\n",
    "miasta_ll_dict = stat_miasta.groupby('Miasto').agg(np.median)['Liczba ludności'].to_dict()\n",
    "miasta_pow_dict = stat_miasta.groupby('Miasto').agg(np.median)['Powierzchnia'].to_dict()\n",
    "wojewodztwa_ll = stat_woj.groupby('Województwo').agg(np.median)['Ogółem'].to_dict()\n",
    "            \n",
    "## fill NA\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "## prepare data\n",
    "%time train, indexers = perform_engineering(train)\n",
    "%time test, dummy = perform_engineering(test, indexers)\n",
    "\n",
    "#########################################\n",
    "#\n",
    "# train specific (only for train)\n",
    "#\n",
    "train['price_per_meter'] = train['price'] / train['area_fixed']\n",
    "\n",
    "dict_mean_price_by_LV = train.groupby('location_v_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LV = train.groupby('location_v_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "dict_mean_price_by_LC = train.groupby('location_c_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LC = train.groupby('location_c_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "dict_mean_price_by_LCC = train.groupby('location_cc_cat').agg(np.mean)['price_per_meter'].to_dict()\n",
    "dict_median_price_by_LCC = train.groupby('location_cc_cat').agg(np.median)['price_per_meter'].to_dict()\n",
    "\n",
    "## prepare price related data\n",
    "%time price_engineering(train)\n",
    "%time price_engineering(test)\n",
    "\n",
    "## fill NA\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  ['monitoring / ochrona', 'taras', 'balkon', 'dwupoziomowe', 'system alarmowy', 'teren zamknięty', 'internet', 'winda', 'piwnica', 'telewizor', 'domofon / wideofon', 'oddzielna kuchnia', 'zmywarka', 'garaż/miejsce parkingowe', 'meble', 'is_primary_market', 'area_float', 'area_fixed', 'rok_budowy_int', 'czynsz_float', 'miasto_ludnosc', 'miasto_gestosc', 'miasto_powierzchnia', 'wojewodztwo_ludnosc', 'stats_visit_ads', 'largest_value', 'lv_mean', 'lv_median', 'lc_mean', 'lc_median', 'lcc_mean', 'lcc_median', 'lv_mean_price_calculated', 'lv_median_price_calculated', 'lc_mean_price_calculated', 'lc_median_price_calculated', 'lcc_mean_price_calculated', 'lcc_median_price_calculated', 'location_v_cat', 'location_c_cat', 'location_cc_cat', 'location_powiat_cat', 'location_miasto_cat', 'stats_created_at_cat', 'stats_updated_at_cat', 'material_cat', 'okna_cat', 'stan_wyk_cat', 'rodzaj_zabudowy_cat', 'ogrzewanie_cat', 'forma_wlasnosci_cat', 'rooms', 'is_private', 'floor_int', 'floors_in_int']\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "#\n",
    "# PREPARE FEATURES\n",
    "#\n",
    "\n",
    "black_list = ['price', 'id']\n",
    "\n",
    "bool_features = train.select_dtypes(include=[np.bool]).columns.values.tolist()\n",
    "\n",
    "cat_feats = [feat for feat in train.columns if 'cat' in feat]\n",
    "cat_feats = cat_feats + ['rooms', 'is_private', 'floor_int', 'floors_in_int']\n",
    "\n",
    "numeric_features = train.select_dtypes(include=[np.float64, np.int64, np.int8]).columns.values\n",
    "numeric_features = [feat for feat in numeric_features if feat not in (black_list + cat_feats) ]\n",
    "\n",
    "feats = bool_features + numeric_features + cat_feats\n",
    "\n",
    "feats = [feat for feat in feats if feat not in (black_list)]\n",
    "\n",
    "X = train[ feats ].values\n",
    "y = train[ 'price' ].values\n",
    "\n",
    "print(\"Selected features: \", feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global fair_constant \n",
    "\n",
    "def fair_obj(y_true, y_pred):\n",
    "    x = y_pred - y_true\n",
    "    \n",
    "    global fair_constant \n",
    "\n",
    "    den = abs(x) + fair_constant\n",
    "    \n",
    "    grad = fair_constant * x / den\n",
    "    hess = (fair_constant * fair_constant) / (den * den)\n",
    "    \n",
    "    return grad, hess\n",
    "\n",
    "xgb_params_1 = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 8, \n",
    "    'n_estimators': 2500, \n",
    "    'learning_rate': 0.04, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 4096\n",
    "}\n",
    "\n",
    "xgb_params_2 = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 14, \n",
    "    'n_estimators': 420, \n",
    "    'learning_rate': 0.056693922378212164, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 2018\n",
    "}\n",
    "\n",
    "xgb_params_s = {\n",
    "    'objective': fair_obj,\n",
    "    \n",
    "    'n_jobs': 4, \n",
    "    'max_depth': 8, \n",
    "    'n_estimators': 200, \n",
    "    'learning_rate': 0.05, \n",
    "    'min_child_weight': 8, \n",
    "    'random_state': 2018\n",
    "}\n",
    "\n",
    "shift = price_shift\n",
    "fair_constant = 13259.556042072305\n",
    "y_log = np.log(y + shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1\n",
      "x1 R2:  0.7247714132123868\n",
      "x1 MAE:  47161.945\n",
      "x2 R2:  0.7094368241853568\n",
      "x2 MAE:  48387.176\n",
      "x_s R2:  0.7218475514368436\n",
      "x_s MAE:  46858.848\n",
      "x_f R2:  0.7229471094273049\n",
      "x_f MAE:  45127.67615881888\n",
      "fold:  2\n",
      "x1 R2:  0.7831547528623674\n",
      "x1 MAE:  45913.043\n",
      "x2 R2:  0.7701184785436026\n",
      "x2 MAE:  46379.004\n",
      "x_s R2:  0.7303429703061826\n",
      "x_s MAE:  45872.496\n",
      "x_f R2:  0.7317795671628913\n",
      "x_f MAE:  44085.40977913655\n",
      "fold:  3\n",
      "x1 R2:  0.8444629860599884\n",
      "x1 MAE:  45038.836\n",
      "x2 R2:  0.832386065000086\n",
      "x2 MAE:  45577.066\n",
      "x_s R2:  0.8444881999416802\n",
      "x_s MAE:  44748.945\n",
      "x_f R2:  0.8462224655582088\n",
      "x_f MAE:  42900.029653821955\n",
      "fold:  4\n",
      "x1 R2:  0.7695790347437557\n",
      "x1 MAE:  46504.695\n",
      "x2 R2:  0.7760659184212069\n",
      "x2 MAE:  46376.688\n",
      "x_s R2:  0.7736475834946668\n",
      "x_s MAE:  45973.773\n",
      "x_f R2:  0.7745988069745299\n",
      "x_f MAE:  43956.976237819435\n",
      "fold:  5\n",
      "x1 R2:  0.841226168567879\n",
      "x1 MAE:  44010.645\n",
      "x2 R2:  0.8330127716367112\n",
      "x2 MAE:  44638.05\n",
      "x_s R2:  0.8415169769399039\n",
      "x_s MAE:  43672.62\n",
      "x_f R2:  0.8420537544378636\n",
      "x_f MAE:  42325.99187794431\n",
      "fold:  6\n",
      "x1 R2:  0.7519884813885502\n",
      "x1 MAE:  45154.02\n",
      "x2 R2:  0.7524573317200685\n",
      "x2 MAE:  45220.63\n",
      "x_s R2:  0.7433173465442569\n",
      "x_s MAE:  45178.715\n",
      "x_f R2:  0.8903201555542407\n",
      "x_f MAE:  41700.49947062952\n",
      "x1_R2 0.7858638061391545 0.04406662741542262\n",
      "x1_MAE 45630.527 1032.021\n",
      "x2_R2 0.7789128982511718 0.04358601618775211\n",
      "x2_MAE 46096.438 1195.0973\n",
      "x_s_R2 0.7758601047772556 0.05012273622606407\n",
      "x_s_MAE 45384.234 1011.2608\n",
      "x_f_R2 0.8013203098525067 0.062301286482851215\n",
      "x_f_MAE 43349.430529695106 1157.677000091901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import r2_score as R2 \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def modPrice(x,limit):\n",
    "    if x['largest_value'] == 0:\n",
    "        return x['XGB_s_results']\n",
    "    if (abs(x['XGB_s_results'] - x['largest_value']) < limit):\n",
    "        return x['largest_value']\n",
    "    \n",
    "    return x['price']\n",
    "\n",
    "y_log = np.log(y + shift)\n",
    "    \n",
    "cv = KFold(n_splits=6, shuffle=True, random_state=2018)\n",
    "\n",
    "scores = {\n",
    "    'x1_R2' : [],\n",
    "    'x1_MAE' : [],\n",
    "    'x2_R2' : [],\n",
    "    'x2_MAE' : [],\n",
    "    'x_s_R2' : [],\n",
    "    'x_s_MAE' : [],\n",
    "    'x_f_R2' : [],\n",
    "    'x_f_MAE' : []\n",
    "}\n",
    "\n",
    "def perform_scoring(m, y_true, y_log_pred):\n",
    "    y_log_pred[ y_log_pred < 0 ] = 1e-6\n",
    "\n",
    "    y_pred = np.exp( y_log_pred ) - shift\n",
    "\n",
    "    score = R2(y_true, y_pred)\n",
    "    print(m + \" R2: \", score)\n",
    "    scores[m + '_R2'].append(score)\n",
    "    \n",
    "    score = mae(y[test_idx], y_pred)\n",
    "    print(m + \" MAE: \", score)\n",
    "    scores[m + '_MAE'].append(score)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    fold += 1\n",
    "    print(\"fold: \", fold)\n",
    "    \n",
    "    # first model\n",
    "    model = XGBRegressor(**xgb_params_1)\n",
    "    model.fit(X[train_idx], y_log[train_idx])\n",
    "    y_log_pred = model.predict(X[test_idx])\n",
    "    perform_scoring('x1', y[test_idx], y_log_pred)\n",
    "    \n",
    "    train['XGB_1_results'] = model.predict(X)\n",
    "    \n",
    "    # second model\n",
    "    model = XGBRegressor(**xgb_params_2)\n",
    "    model.fit(X[train_idx], y_log[train_idx])\n",
    "    y_log_pred = model.predict(X[test_idx])\n",
    "    perform_scoring('x2', y[test_idx], y_log_pred)\n",
    "    \n",
    "    train['XGB_2_results'] = model.predict(X)\n",
    "    \n",
    "    # stacked\n",
    "    stacked_feats = feats + ['XGB_1_results', 'XGB_2_results']\n",
    "\n",
    "    X_stacked = train[ stacked_feats ].values\n",
    "    y_stacked = train[ 'price' ].values\n",
    "\n",
    "    y_stacked_log = np.log(y_stacked + shift)\n",
    "\n",
    "    model = XGBRegressor(**xgb_params_s)\n",
    "    model.fit(X_stacked[train_idx], y_stacked_log[train_idx])\n",
    "    \n",
    "    y_log_pred = model.predict(X_stacked[test_idx])\n",
    "    perform_scoring('x_s', y_stacked[test_idx], y_log_pred)\n",
    "    \n",
    "    y_log_pred = model.predict(X_stacked)\n",
    "    y_log_pred[ y_log_pred < 0 ] = 1e-6\n",
    "    y_pred = np.exp( y_log_pred ) - shift\n",
    "    train['XGB_s_results'] = y_pred\n",
    "    \n",
    "    #function\n",
    "    train['XGB_s_results_mod'] = train.apply(lambda x: modPrice(x,225000), axis=1 )\n",
    "    y_pred = train['XGB_s_results_mod'].values\n",
    "    \n",
    "    score = R2(y[test_idx],y_pred[test_idx])\n",
    "    print(\"x_f R2: \", score)\n",
    "    scores['x_f_R2'].append(score)\n",
    "    score = mae(y[test_idx],y_pred[test_idx])\n",
    "    print(\"x_f MAE: \", score)\n",
    "    scores['x_f_MAE'].append(score)\n",
    "    \n",
    "for s in scores:\n",
    "    print(s, np.mean(scores[s]), np.std(scores[s]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
